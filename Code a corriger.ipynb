{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "648c8bff",
   "metadata": {},
   "source": [
    "# pré-traitement adaptation casse\n",
    "Si le mot au début de la ligne est en majuscule, on le met en minuscule s'il valide les deux conditions suivantes :\n",
    "\n",
    "- Il \"existe en minuscule dans le Glaff\"\n",
    "\n",
    "- Il \"n'es pas pas dans la ressource de noms de lieux\"\n",
    "\n",
    "Par exemple, si j'ai :\n",
    "\n",
    "Il est maxi Docteur Schweitzer Il- --> il\n",
    "\n",
    "Maximum et maxibus Maximum --> maximum\n",
    "\n",
    "Maxistère et termaxus --> maxistère\n",
    "\n",
    "par contre dans\n",
    "\n",
    "\"Paris et province\" --> Paris ne bouge pas car s'il existe en minuscule dans le Glaff il est présent dans la ressource\n",
    "\n",
    "La véritable \"recréation\" de phrases ce sera une étape pour plus tard, car ça va être assez compliqué !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87687b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ouverture et lecture des json\n",
    "import json\n",
    "def ouvrir_json(chemin):\n",
    "    f = open(chemin, encoding=\"utf-8\")\n",
    "    toto = json.load(f)\n",
    "    f.close()\n",
    "    return toto\n",
    "\n",
    "def ecrire_fichier(chemin, contenu):\n",
    "  w = open(chemin, \"w\", encoding=\"utf-8\")\n",
    "  w.write(contenu)\n",
    "  w.close()\n",
    "def lire_fichier(chemin):\n",
    "  f = open(chemin, \"r\", encoding=\"utf-8\")\n",
    "  chaine = f.read()\n",
    "  f.close()\n",
    "  return chaine\n",
    "def Splittxt(txt):\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"(\\w+,\\w+|\\w+-\\w+|\\w+\\.\\w+\\.\\w+|\\w+\\S|\\w+|\\S|\\w+\\S|\\?|\\!)\")\n",
    "    txt_split = tokenizer.tokenize(txt)\n",
    "    return txt_split\n",
    "def Splittxt2(txt):\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"(\\w+'|\\w+-\\w+|\\w+|\\S|\\w+\\S)\")\n",
    "    txt_split = tokenizer.tokenize(txt)\n",
    "    return txt_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14780918",
   "metadata": {},
   "source": [
    "# création d'une liste des lieux de paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3c3103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import re\n",
    "\n",
    "chemin = glob.glob('lieux_paris/*/*')\n",
    "vrai_entite_nomme = []\n",
    "dic_lieu = {}\n",
    "for i in chemin:\n",
    "    lieux_de_paris = ouvrir_json(i)\n",
    "    for lieu in lieux_de_paris:\n",
    "        #print(lieu)\n",
    "        vrai_entite_nomme.append(lieu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efe2ecc",
   "metadata": {},
   "source": [
    "# Récupération du glaff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75590b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1082688\n",
      "1082688\n",
      "météoriser\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#voc_glaff = []\n",
    "with open(\"freq_glaff_10000.json\") as f:\n",
    "    dic = json.load(f)\n",
    "    print(len(dic))\n",
    "    voc_glaff = set(dic.keys()) \n",
    "    print(len(voc_glaff))\n",
    "\n",
    "mot = \"météoriser\"\n",
    "if mot in voc_glaff:\n",
    "    print(mot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37cc579",
   "metadata": {},
   "source": [
    "# Execution du code sur une liste avant de l'executer sur le corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aa50abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"Je\"  dans : \"Je oui bonjour\" \n",
      "Je je suis bien en majuscule\n",
      "le mot est dans glaff\n",
      "je suis pas un nugget \n",
      "['Je oui bonjour', 'Fzefjkgnsd suis moi est mini', 'Mini-moke et mini-jupe', 'Tout oui mal-honnete oui, bonjour'] \n",
      "\n",
      " \"Fzefjkgnsd\"  dans : \"Fzefjkgnsd suis moi est mini\" \n",
      "Fzefjkgnsd je suis bien en majuscule\n",
      "le mot est pas dans glaff\n",
      "['je oui bonjour', 'Fzefjkgnsd suis moi est mini', 'Mini-moke et mini-jupe', 'Tout oui mal-honnete oui, bonjour'] \n",
      "\n",
      " \"Mini-moke\"  dans : \"Mini-moke et mini-jupe\" \n",
      " \"Tout\"  dans : \"Tout oui mal-honnete oui, bonjour\" \n",
      "Tout je suis bien en majuscule\n",
      "le mot est dans glaff\n",
      "je suis pas un nugget \n",
      "['je oui bonjour', 'fzefjkgnsd suis moi est mini', 'Mini-moke et mini-jupe', 'Tout oui mal-honnete oui, bonjour'] \n",
      "\n",
      "['je oui bonjour', 'fzefjkgnsd suis moi est mini', 'Mini-moke et mini-jupe', 'tout oui mal-honnete oui , bonjour']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "#création d'une liste de ligne pour simuler la poésie.\n",
    "lignes_chanson = [\"Je oui bonjour\", \n",
    "                  \"Fzefjkgnsd suis moi est mini\", \n",
    "                  \"Mini-moke et mini-jupe\", #\"Mini-moke\" ne sera pas mis en minuscule comme les autres lignes\n",
    "                  \"Tout oui mal-honnete oui, bonjour\"]\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "#boucle qui parcours ma liste lignes_chanson\n",
    "for z in lignes_chanson:\n",
    "    expr = re.compile(\"^(\\w+'|\\w+-\\w+|\\w+)\")\n",
    "    match = expr.finditer(z)\n",
    "    #ici je créer une expression pour récuperer tous les mots en début de ligne, \n",
    "    #certain commençant par \"j'\" ou \"c'\" d'autre par un tiret \"un-mot\", je ne sais pas s'il y a\n",
    "    #d'autre mot différent.\n",
    "#------------------------------------------------------------------------------------------------------------ \n",
    "    for m in match:\n",
    "        mot = m.group(0) #la variable mot prend la chaine de caractère trouvé par mon match.\n",
    "        print(\"\"\" \"{}\"  dans : \"{}\" \"\"\".format(mot, z)) #affiche le mot dans quel ligne il se trouve.\n",
    "        if mot.istitle(): #si le mot possède une majuscule je le met sans maj.\n",
    "            mot = mot.lower()\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "            if mot in voc_glaff:                 #s'il est dans le glaff et qu'il correspond \n",
    "                print(\"le mot est dans glaff\")   #a un lieu de ma liste des lieux\n",
    "                if mot in vrai_entite_nomme:     #SINON je l'affiche .\n",
    "                    print(\"le mot est un nugget \")\n",
    "                else:\n",
    "                    print(\"je suis pas un nugget \") \n",
    "                    liste_mots = Splittxt2(z)      #permet de découper ma ligne en liste de mot.\n",
    "                    liste_mots[0] = mot            #le mot en début de ligne je le remplace par mot.\n",
    "                    nouvelle_ligne = \" \".join(liste_mots)  #je reassemble ma ligne.\n",
    "                    print(lignes_chanson, \"\\n\")\n",
    "                    res = [elem.replace(z,nouvelle_ligne) for elem in lignes_chanson]  #je remplace \n",
    "                    lignes_chanson = res               #l'ancienne ligne par une nouvelle ligne.                            \n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "            if mot not in voc_glaff:            #s'il est pas dans le glaff je fait le même procédé ↑.\n",
    "                print(\"le mot est pas dans glaff\")\n",
    "                liste_mots = Splittxt2(z)\n",
    "                liste_mots[0] = mot\n",
    "                nouvelle_ligne = \" \".join(liste_mots)\n",
    "                print(lignes_chanson, \"\\n\")\n",
    "                res = [elem.replace(z,nouvelle_ligne) for elem in lignes_chanson]\n",
    "                lignes_chanson = res\n",
    "\n",
    "        \n",
    "print(lignes_chanson)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f72e2b5",
   "metadata": {},
   "source": [
    "# On observe que le traitement fonctionne partout sauf pour Mini-moke"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
